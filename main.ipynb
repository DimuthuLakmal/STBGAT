{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "\n",
    "from data_loader.data_loader import DataLoader\n",
    "from models.sgat_transformer.sgat_transformer import SGATTransformer\n",
    "from test import test\n",
    "from train import train\n",
    "from utils.masked_mae_loss import Masked_MAE_Loss\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run(epochs: int, data_loader: DataLoader, device: str, model_input_path: str, model_output_path: str,\n",
    "        load_saved_model: bool, model_configs: dict, log_file):\n",
    "    model = SGATTransformer(device=device,\n",
    "                            sgat_first_in_f_size=1,\n",
    "                            sgat_n_layers=1,\n",
    "                            sgat_out_f_sizes=[16],\n",
    "                            sgat_n_heads=[8],\n",
    "                            sgat_alpha=0.2,\n",
    "                            sgat_dropout=0.2,\n",
    "                            sgat_edge_dim=model_configs['edge_dim'],\n",
    "                            transformer_merge_emb=model_configs['merge_emb'],\n",
    "                            transformer_enc_seq_len=model_configs['enc_seq_len'],\n",
    "                            transformer_dec_seq_len=model_configs['dec_seq_len'],\n",
    "                            transformer_dec_seq_offset=model_configs['dec_seq_offset'],\n",
    "                            transformer_input_dim=model_configs['input_dim'],\n",
    "                            transformer_cross_attn_features=model_configs['cross_attn_features'],\n",
    "                            transformer_per_enc_feature_len=model_configs['per_enc_feature_len'],\n",
    "                            transformer_dec_out_start_idx=model_configs['dec_out_start_idx'],\n",
    "                            transformer_dec_out_end_idx=model_configs['dec_out_end_idx'],\n",
    "                            transfomer_emb_dim=16,\n",
    "                            # input to transformers will be embedded to this dim. Value is similar the last element of sgat_out_f_sizes if both embeddings merge together\n",
    "                            transformer_n_layers=4,\n",
    "                            transformer_expansion_factor=4,\n",
    "                            transformer_n_heads=8,\n",
    "                            transformer_enc_features=model_configs['enc_features'],  # number of encoders\n",
    "                            transformer_out_dim=1,\n",
    "                            transformer_dropout=0.2,\n",
    "                            transformer_lookup_index=True).to(device)\n",
    "\n",
    "    if load_saved_model:\n",
    "        model.load_state_dict(torch.load(model_input_path))\n",
    "\n",
    "    # mse_loss_fn = nn.L1Loss()\n",
    "    mse_loss_fn = Masked_MAE_Loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=15, T_mult=1, eta_min=0.00005)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=2, gamma=0.75)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    min_val_loss = np.inf\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"LR: {lr_scheduler.get_last_lr()}\")\n",
    "        log_file.write(f\"LR: {lr_scheduler.get_last_lr()}\\n\")\n",
    "\n",
    "        mae_train_loss, rmse_train_loss, mape_train_loss = train(model=model,\n",
    "                                                                 data_loader=data_loader,\n",
    "                                                                 optimizer=optimizer,\n",
    "                                                                 loss_fn=mse_loss_fn,\n",
    "                                                                 device=device,\n",
    "                                                                 seq_offset=model_configs['dec_seq_offset'])\n",
    "\n",
    "        mae_val_loss, rmse_val_loss, mape_val_loss = test(_type='test',\n",
    "                                                          model=model,\n",
    "                                                          data_loader=data_loader,\n",
    "                                                          device=device,\n",
    "                                                          seq_offset=model_configs['dec_seq_offset'])\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        print(f\"Epoch: {epoch} | mae_train_loss: {mae_train_loss} | rmse_train_loss: {rmse_train_loss}\"\n",
    "              f\" | mape_train_loss: {mape_train_loss} | mae_val_loss: {mae_val_loss}\"\n",
    "              f\" | rmse_val_loss: {rmse_val_loss} | mape_val_loss: {mape_val_loss}\")\n",
    "        log_file.write(\"Epoch: {epoch} | mae_train_loss: {mae_train_loss} | rmse_train_loss: {rmse_train_loss}\"\n",
    "              f\" | mape_train_loss: {mape_train_loss} | mae_val_loss: {mae_val_loss}\"\n",
    "              f\" | rmse_val_loss: {rmse_val_loss} | mape_val_loss: {mape_val_loss}\\n\")\n",
    "\n",
    "        if min_val_loss > rmse_val_loss:\n",
    "            min_val_loss = rmse_val_loss\n",
    "            best_model_path = model_output_path.format(str(epoch))\n",
    "            torch.save(model.state_dict(), best_model_path)  # saving model\n",
    "            print('Saving Model...')\n",
    "            log_file.write(\"Saving Model...\\n\")\n",
    "\n",
    "    # testing model\n",
    "    print('Testing model...')\n",
    "    log_file.write(\"Testing model...\\n\")\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    mae_test_loss, rmse_test_loss, mape_test_loss = test(_type='test',\n",
    "                                                         model=model,\n",
    "                                                         data_loader=data_loader,\n",
    "                                                         device=device,\n",
    "                                                         seq_offset=model_configs['dec_seq_offset'])\n",
    "\n",
    "    print(f\"mae_test_loss: {mae_test_loss} | rmse_test_loss: {rmse_test_loss} | mape_test_loss: {mape_test_loss}\")\n",
    "\n",
    "    log_file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"config/config.yaml\", \"r\") as stream:\n",
    "    configs = yaml.safe_load(stream)\n",
    "\n",
    "    # data configs\n",
    "    dec_seq_offset = configs['dec_seq_offset']\n",
    "    edge_attr_scaling = configs['edge_attr_scaling'] if configs['edge_attr_scaling'] else True\n",
    "    num_of_vertices = configs['num_of_vertices'] if configs['num_of_vertices'] else 307\n",
    "    points_per_hour = configs['points_per_hour'] if configs['points_per_hour'] else 12\n",
    "    num_for_predict = configs['num_for_predict'] if configs['num_for_predict'] else 12\n",
    "    len_input = configs['len_input'] if configs['len_input'] else 12\n",
    "    num_of_weeks = configs['num_of_weeks']\n",
    "    num_of_days = configs['num_of_days']\n",
    "    num_of_hours = configs['num_of_hours']\n",
    "    num_of_weeks_target = configs['num_of_weeks_target']\n",
    "    num_of_days_target = configs['num_of_days_target']\n",
    "    batch_size = configs['batch_size'] if configs['batch_size'] else 32\n",
    "    epochs = configs['epochs'] if configs['epochs'] else 200\n",
    "    adj_filename = configs['adj_filename'] if configs['adj_filename'] else 'data/PEMS04/PEMS04.csv'\n",
    "    graph_signal_matrix_filename = configs['graph_signal_matrix_filename'] if configs[\n",
    "        'graph_signal_matrix_filename'] \\\n",
    "        else 'data/PEMS04/PEMS04.npz'\n",
    "    dataset_name = configs['dataset_name'] if configs['dataset_name'] else 'PEMS04'\n",
    "    log_filename = configs['log_filename']\n",
    "\n",
    "    graph_enc_input = configs['graph_enc_input'] if configs['graph_enc_input'] else False\n",
    "    graph_dec_input = configs['graph_dec_input'] if configs['graph_dec_input'] else False\n",
    "    non_graph_enc_input = configs['non_graph_enc_input'] if configs['non_graph_enc_input'] else False\n",
    "    non_graph_dec_input = configs['non_graph_dec_input'] if configs['non_graph_dec_input'] else False\n",
    "\n",
    "    # model configs\n",
    "    model_output_path = configs['model_output_path'] if configs[\n",
    "        'model_output_path'] else 'output/model/epoch_{}_model.pt'\n",
    "    model_input_path = configs['model_input_path'] if configs[\n",
    "        'model_input_path'] else 'output/model/epoch_1_model.pt'\n",
    "    load_saved_model = configs['load_saved_model'] if configs['load_saved_model'] else False\n",
    "\n",
    "    input_dim = configs['input_dim'] if configs['input_dim'] else 1\n",
    "    edge_dim = configs['edge_dim'] if configs['edge_dim'] else 1\n",
    "    enc_seq_len = configs['enc_seq_len'] if configs['enc_seq_len'] else 12\n",
    "    dec_seq_len = configs['dec_seq_len'] if configs['dec_seq_len'] else 12\n",
    "    enc_features = configs['enc_features'] if configs['enc_features'] else 5\n",
    "\n",
    "    merge_emb = configs['merge_emb'] if configs['merge_emb'] else False\n",
    "    device = configs['device'] if configs['device'] else 'cpu'\n",
    "    cross_attn_features = configs['cross_attn_features'] if configs['cross_attn_features'] else 3\n",
    "    per_enc_feature_len = configs['per_enc_feature_len'] if configs['per_enc_feature_len'] else 12\n",
    "    dec_out_start_idx = configs['dec_out_start_idx']\n",
    "    dec_out_end_idx = configs['dec_out_end_idx']\n",
    "\n",
    "log_file = open(log_filename, '+w')\n",
    "\n",
    "data_configs = {\n",
    "    'num_of_vertices': num_of_vertices,\n",
    "    'points_per_hour': points_per_hour,\n",
    "    'num_for_predict': num_for_predict,\n",
    "    'len_input': len_input,\n",
    "    'num_of_weeks': num_of_weeks,\n",
    "    'num_of_days': num_of_days,\n",
    "    'num_of_hours': num_of_hours,\n",
    "    'num_of_days_target': num_of_days_target,\n",
    "    'num_of_weeks_target': num_of_weeks_target,\n",
    "    'batch_size': batch_size,\n",
    "    'dec_seq_offset': dec_seq_offset,\n",
    "    'graph_enc_input': graph_enc_input,\n",
    "    'graph_dec_input': graph_dec_input,\n",
    "    'non_graph_enc_input': non_graph_enc_input,\n",
    "    'non_graph_dec_input': non_graph_dec_input,\n",
    "    'enc_features': enc_features\n",
    "}\n",
    "data_loader = DataLoader(data_configs)\n",
    "\n",
    "data_loader.load_node_data_file(graph_signal_matrix_filename)\n",
    "# data_loader.load_node_data_astgnn(graph_signal_matrix_filename)\n",
    "data_loader.load_edge_data_file(adj_filename, scaling=edge_attr_scaling)\n",
    "\n",
    "run(data_loader=data_loader,\n",
    "    epochs=epochs,\n",
    "    device=device,\n",
    "    model_input_path=model_input_path,\n",
    "    model_output_path=model_output_path,\n",
    "    load_saved_model=load_saved_model,\n",
    "    log_file=log_file,\n",
    "    model_configs={\n",
    "        'input_dim': input_dim,\n",
    "        'edge_dim': edge_dim,\n",
    "        'enc_seq_len': enc_seq_len,\n",
    "        'dec_seq_len': dec_seq_len,\n",
    "        'enc_features': enc_features,\n",
    "        'dec_seq_offset': dec_seq_offset,\n",
    "        'merge_emb': merge_emb,\n",
    "        'cross_attn_features': cross_attn_features,\n",
    "        'per_enc_feature_len': per_enc_feature_len,\n",
    "        'dec_out_start_idx': dec_out_start_idx,\n",
    "        'dec_out_end_idx': dec_out_end_idx\n",
    "    })"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
